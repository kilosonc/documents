我们是网易云音乐的云原生团队，负责运维基于 GitOps 的 CICD 平台 Horizon。该平台涵盖了多个管控组件，而这些组件的运维过程也存在许多挑战，运维容易出错、没有版本控制、回滚难、协作困难、自动化程度不高。我们需要解决这些问题，以最大限度地减少运维错误，并保证出现故障时能够快速恢复。此外，我们也需要满足多人协作的需求，提高自动化水平等。

## 管控面运维

为了解决上述问题，我们的云原生团队已经实现了一套基于 Gitlab CI 的 GitOps 部署规范流程，用于管控组件的部署。每个运行中的组件都有一个对应的代码仓库和配置仓库。开发人员将修改推送到代码仓库后，经过审核后合并到主分支并打出对应的镜像。然后，只需要修改 GitOps 部署仓库，就可以将修改部署到线上。

1. 首先，开发人员需要 Fork 一份配置仓库的代码，通常是一个基于 Helm 的 Chart。在该仓库中，只需修改 values.yaml 文件，通常就可以满足开发人员的需求。而 templates 文件则打包放在 Harbor 中。在 Chart.yaml 文件的 dependency 字段中引用这些 templates，这样我们就可以在多个环境中部署相同的组件。通过将 templates 抽象出来，我们可以将统一的配置放在 templates 中，而在各自的配置仓库中，则可以放置不同的配置，兼顾统一和灵活。

2. 开发者在修改配置仓库后，需要将修改推到仓库中，并向 master 分支提交 MR。这时会触发流水线，验证修改是否正确。

3. 通过验证后，开发者需要请求团队中的其他人帮忙 review，通过检查后，合入主分支。

4. 合入主分支，会触发另一条流水线，将修改应用到 Kubernetes 中。

5. 开发者如果观察到本次修改存在任何问题，并且无法快速恢复，那么可以找到上一次成功的发布，重新跑一下对应的流水线，就可以快速回滚。

![[Pasted image 20230606193220.jpg]]

以上流程，我们通过引入测试流水线和 Reviewer 降低了出错的概率，通过重新运行部署流水线完成了快速回滚，通过 commit 记录每次部署的操作者，通过自动化部署减少了人工介入，解决了绝大部分传统部署过程中的问题。

## Horizon 应用部署

经过上面的实践，我们已经见识到了 GitOps 的强大。所以我们将 GitOps 应用到了 Horizon 中。Horizon 中的 GitOps 逻辑与上述逻辑略有不同，它底层使用 Argo CD 作为 GitOps 引擎。
GitOps 引擎会监听 GitOps 仓库和Kubernetes资源。Horizon 会为其中的每个应用创建对应的 GitOps 仓库，GitOps 仓库有两个 branch，一个为 master 分支，通过 Argo CD与 Kubernetes 中的相关资源对应；另一个为 gitops 分支，gitops 分支中包含了用户修改之后还未生效的配置。

当用户发布或者构建发布时，Horizon 会将 gitops 分支合并到 master 分支中。因为 Argo CD 监听了 GitOps 仓库中的 master 分支，所以 Argo CD 会感知到变化。通过和 Kubernetes 中的相关资源比对，如果不一致则触发一次同步，将 GitOps 仓库中的配置，应用到 Kubernetes 中。完成一次部署。

![[Pasted image 20230606201754.jpg]]

Horizon在合并分支时，会将相关参数，比如操作人、时间、修改等信息记录到 description 中，方便审阅。
Horizon中的回滚，是将对应的修改再合并到 master 分支。

## GitOps 的优势

经过以上两个例子，你可以感受到 GitOps 有许多优势：

1. 增强了开发团队的协作能力：GitOps可以帮助开发团队更好地协作，将应用程序的配置和部署流程存储在Git仓库中，使得整个团队可以更加透明和高效地工作。
2. 提高了应用程序的可靠性和可用性：GitOps使用自动化部署和测试来提高应用程序的可靠性和可用性，减少了手动操作的错误和风险。
3. 降低了操作失误的风险：GitOps的自动化部署和测试可以降低操作失误的风险，并提高整个团队的运维能力。
4. 提高了部署速度和效率：GitOps可以自动部署应用程序，并快速地检测和解决问题，从而提高整个团队的部署速度和效率。

现在 Horizon 已经在 Github 上开源，如果你对 GitOps 或者 Horizon 感兴趣，可以加入我们的[微信群](https://github.com/horizoncd/horizon#contact-us)与我们进一步交流

## FAQ

我们在与外部用户的交流中发现，外部用户有很多使用 istio 与 deployment 实现流量灰度。这样需要实现一个 svc 对应多个 deployment 的场景。
![[6847c91db7e58bfa4887ed27d8abffb3.png]]